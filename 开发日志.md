# 😱 小项目

需求：前端发送请求，通过解析请求返回相应的文件。如果文件存在与内存中则需要从内存中加载返回。不然就从磁盘返回，并且将数据写到内存中。

思路：用标准库写一个网络程序，监听端口，解析请求并返回数据，~~每个请求使用一个协程完成工作~~。go中通过ListenAndServe方法监听一个端口的话，方法内部会使用go关键字针对每个连接单独启动一个协程工作。

# 阶段一

写了一个handleFunc如下，主要功能就是给前端返回一个文件。这不是最终效果，这里的疑问是


:::info
为什么以字节流写入ResponeWrite的文件，浏览器能够直接识别并且显示出来

:::

答案是**HTTP的返回头**。浏览器会根据返回头中的content-type来判断文件的格式，虽然这里没有显式地指定返回头中的content-type，但是golang会根据文件的拓展名自动填充content-type字段。

```go
func uploadFile(w http.ResponseWriter, r *http.Request) {

	// 打开一个文件
	file, err := os.Open("../static/1.jpg")
	if err != nil {
		fmt.Println("err:", err)
		return
	}
	// 延迟关闭，避免内存泄露
	defer file.Close()

	// 采用bufio读取文件，提升效率
	reader = bufio.NewReader(file)
	buf := make([]byte, 50)
	bytes := make([]byte, 0)

	// 循环读取文件，以字节流的形式
	for {
		size, err := reader.Read(buf)
		// 当读到文件末尾时
		if size == 0 || err == io.EOF {
			break
		}
		bytes = append(bytes, buf[:size]...)
	}

	// 写入ResponeWrite，返回给浏览器
	w.Write(bytes)
}
```

# 阶段二

## 完成度

现在已经基本实现了功能


1. 实现带缓存的文件上传
2. 将一些基本的配置参数通过json文件设置，需要注意的是配置文件需要与程序在同一层目录，否侧程序会找不到配置文件的路径
3. 实现了一个简单的日志功能，日志文件的路径可以通过配置文件设置，默认为与程序同一级目录

未完成的功能


1. 带策略的缓存逻辑

## 简单说明及遇到的问题

### 程序主要由几个功能组成

* 启动WebServer监听端口，从url解析参数，并且通过参数合成文件路径以及文件名称
* 查询redis是否存在数据，若有则直接返回
* 查询硬盘中是否存在数据，若有则返回并加载至redis，若无则返回错误

这里给出几个主要功能函数的代码

* 获取文件

```go
/*
获取文件，并将文件发送给浏览器
具体功能:
redis中存在就从redis中加载,redis中不存在就从硬盘加载，并将内容加载到redis中
*/
func getFile(fileName string, filePath string) (data []byte, err error) {

	// 尝试从redis中获取数据
	data, err = getFileFromRedis(fileName) //这里fileName还需调整，这个fileName此时并不唯一
	// 没有错误，说明文件在redis中，直接返回
	if err == nil {
		// fmt.Println("get from redis")
		logger.Println("get from redis")
		return
	}

	// 如果程序运行到这里，说明内存没有命中，那么从硬盘中加载

	// 获得文件的字节流
	data, err = getFileStream(filePath)
	if err != nil {
		// fmt.Println("getFileStream err:", err)
		logger.Printf("getFileStream err:%v\n", err)
		return
	}
	/*
		在这里加入逻辑，决定缓存至内存中的策略
	*/

	// 将获取到的字节流送到redis中
	err = loadFileToRedis(fileName, data)
	if err != nil {
		fmt.Println("loadFileToRedis err:", err)
		logger.Printf("loadFileToRedis err:%v\n", err)
		return
	}

	// 都没有错误，返回数据
	fmt.Println("get from disk")
	logger.Println("get from disk")
	return
}
```

* 获取文件字节流

```go
func getFileStream(filePath string) (fileStream []byte, err error) {

	// 打开一个文件
	file, err := os.Open(filePath)
	if err != nil {
		// fmt.Println("err:", err)
		logger.Printf("open file err:%v", err)
		return
	}
	// 延迟关闭，避免内存泄露
	defer file.Close()

	// 采用bufio读取文件，提升效率
	reader := bufio.NewReader(file)
	buf := make([]byte, 50)
	fileStream = make([]byte, 0)

	// 循环读取文件，以字节流的形式
	for {
		size, err := reader.Read(buf)
		// 当读到文件末尾时
		if size == 0 || err == io.EOF {
			break
		}
		fileStream = append(fileStream, buf[:size]...)
	}

	return fileStream, nil
}
```

* 对redis的操作

```go
// 从redis获取文件
func getFileFromRedis(key string) (result []byte, err error) {
	str, err := rdb.Get(context.Background(), key).Result()
	if err != nil {
		// 结果为空，redis中不存在数据
		if err == redis.Nil {
			fmt.Println("文件不在内存中")
			logger.Printf("get file from redis err:%v\n", err)
			return
		}
	}
	return []byte(str), err
}

// 将文件加载至redis中
func loadFileToRedis(key string, fileStream []byte) (err error) {
	err = rdb.Set(context.Background(), key, fileStream, 0).Err()
	logger.Printf("set file to redis err:%v\n", err)
	return
}
```

### 遇到的问题


1. 关于文件读写问题

   文件的读写一般是是通过io/ioutil配合os包实现的，由os包打开文件，交由io进行文件的的读写操作，某些对性能有要求的场景下，可以使用带缓冲的bufio代替io进行读写操作。

   > os包提供了操作系统函数的不依赖平台的接口。os包的接口规定为在所有操作系统中都是一致的。非公用的属性可以从操作系统特定的[syscall](http://godoc.org/syscall)包获取。
2. 关于json

   go中的encoding/json提供了简单易用的序列化json的功能。对于将结构体序列化为字节流已经很熟悉了，这里讲讲通过序列化将json写入文件中。可以通过Encoder对象实现，Encoder对象会将数据写入到输出流中，下面通过简单的示例说明。

   ```go
   package main
   
   import (
   	"encoding/json"
   	"fmt"
   	"os"
   )
   
   type Person struct {
   	Name  string `json:"name"`
   	Age   int    `json:"age"`
   	Hobby string `json:"hobby"`
   }
   
   func main() {
   
   	person := Person{
   		Name:  "tom",
   		Age:   25,
   		Hobby: "coding",
   	}
   
   	jsonFile, err := os.Create("./test.json")
   	if err != nil {
   		fmt.Println("err:", err)
   	}
   	defer jsonFile.Close()
   
   	// 这里jsonFile就是你的输出流
   	encoder := json.NewEncoder(jsonFile)
   	// 这里SetIndent为了让输出格式化，不然文件里的内容会都在一行
   	// prefix表示前缀，一般为空
   	// indent表示缩进，一般为几个空格
   	encoder.SetIndent("", "    ")
   	encoder.Encode(&person)
   
   }
   
   ```

   这段代码会生成一个test.json文件，文件里面就是Person结构体的数据，如下

   ```json
   {
       "name": "tom",
       "age": 25,
       "hobby": "coding"
   }
   
   ```
3. 日志问题

   go提供了log包，可以用来实现记录日志的一些功能，比较简单，不做说明。

# 阶段三

## 完成度

新增加了一个配置redis数据库的文件，修复了一个逻辑上的问题

## 遇到的问题

遇到了一个比较严重的逻辑上的bug：在redis没有启用的情况下，程序无法从硬盘中获取数据返回给浏览器，导致整个程序的功能都无法执行。这属于程序的健壮性的问题，程序的结构不佳或考虑的地方不全导致的。

主要的问题出现在getFile函数上,在第35行中，出现了错误直接返回了。

```go
/*
获取文件，并将文件发送给浏览器
具体功能:
redis中存在就从redis中加载,redis中不存在就从硬盘加载，并将内容加载到redis中
*/
func getFile(fileName string, filePath string) (data []byte, err error) {

	// 尝试从redis中获取数据
	data, err = getFileFromRedis(fileName) //这里fileName还需调整，这个fileName此时并不唯一
	// 没有错误，说明文件在redis中，直接返回
	if err == nil {
		// fmt.Println("get from redis")
		logger.Println("get from redis")
		return
	}

	// 如果程序运行到这里，说明内存没有命中，那么从硬盘中加载

	// 获得文件的字节流
	data, err = getFileStream(filePath)
	if err != nil {
		// fmt.Println("getFileStream err:", err)
		logger.Printf("getFileStream err:%v\n", err)
		return
	}
	/*
		在这里加入逻辑，决定缓存至内存中的策略
	*/

	// 将获取到的字节流送到redis中
	err = loadFileToRedis(fileName, data)
	if err != nil {
		fmt.Println("loadFileToRedis err:", err)
		logger.Printf("loadFileToRedis err:%v\n", err)
		return
	}

	// 都没有错误，返回数据
	fmt.Println("get from disk")
	logger.Println("get from disk")
	return
}
```

返回后，会返回到调用他的函数**handleRequestFile**,程序会在**handleRequestFile**的第10行继续执行，此时的data为数据的字节流，err为*net.OpErr*中的timeout，此时程序从11行进入**if**语句执行。但是**if**里面只对文件是否存在的错误进行处理，对现在出现的timeout则没有处理，就在16行直接返回了。也没有将从磁盘查询出来的文件写入`http.ResponseWriter`返回浏览器，导致浏览器页面什么反应都没有。

```go
// 处理请求文件逻辑
func handleRequestFile(w http.ResponseWriter, r *http.Request) {

	// 获取参数,拼接出文件名及文件的磁盘路径
	query := r.URL.Query()
	fileName := query.Get("file") + serverConfig.Suffix
	filePath := serverConfig.Prefix + fileName

	// 获取文件,以[]byte形式
	data, err := getFile(fileName, filePath)
	if err != nil {
		logger.Printf("getFile err:%v\n", err)
		if errors.Is(err, os.ErrNotExist) {
			fmt.Fprint(w, "您请求的数据服务器中不存在，请联系管理员")
		}	
		return
	}

	// 指定返回头中的disposition-content,让浏览器以附件的形式下载文件
	w.Header().Set("content-disposition", "attachment;filename="+fileName)
	w.Write(data)
}
```

## 解决方案

知道了原因之后解决起来就容易了。将`handleRequestFile()`函数的错误判断增加即可，在加上处理逻辑就可以解决这个问题。同时也对`getFile()`函数进行了一些改变，使得逻辑更加合理。下面是修改过后的代码，但是修改过后的代码仍旧存在着一些问题：浏览器要经过10s(最少)的时间才能有反应。这是因为redis没有启动的话，执行操作需要等待完两个最大连接等待时间(可以自定义)才会从硬盘中加载数据返回，这会带来糟糕的用户体验。这两个最大连接时间来自`getFile()`函数中的`rdb.Exists(context.Background(), fileName).Result()`和`getFileFromRedis()`函数中的`rdb.Get(context.Background(), key).Result()`

```go
// 处理请求文件逻辑
func handleRequestFile(w http.ResponseWriter, r *http.Request) {

	// 获取参数,拼接出文件名及文件的磁盘路径
	query := r.URL.Query()
	fileName := query.Get("file") + serverConfig.Suffix
	filePath := serverConfig.Prefix + fileName

	// 获取文件,以[]byte形式
	data, err := getFile(fileName, filePath)
	if err != nil {
		logger.Printf("getFile err:%v\n", err)
		if errors.Is(err, os.ErrNotExist) {
			fmt.Fprint(w, "您请求的数据服务器中不存在，请联系管理员")
		}
		opErr, ok := err.(*net.OpError)
		if ok {
			if opErr.Timeout() {
				// 指定返回头中的disposition-content,让浏览器以附件的形式下载文件
				w.Header().Set("content-disposition", "attachment;filename="+fileName)
				w.Write(data)
			}
		}
		return
	}

	// 指定返回头中的disposition-content,让浏览器以附件的形式下载文件
	w.Header().Set("content-disposition", "attachment;filename="+fileName)
	w.Write(data)
 }
 
```

```go

/*
获取文件，并将文件发送给浏览器
具体功能:
redis中存在就从redis中加载,redis中不存在就从硬盘加载，并将内容加载到redis中
*/
func getFile(fileName string, filePath string) (data []byte, err error) {

	// 1.尝试从redis中获取数据
	// 判断key是否存在于redis中
	exist, err := rdb.Exists(context.Background(), fileName).Result()
	if err != nil {
		logger.Println("redis connection err:", err)
		// 猜测：获取不在redis中的数据会直接返回，浏览器没有任何数据
		// err:redis.Nil
		// return
	}

	// 文件存在，直接获取返回
	if exist == 1 {
		// 这里文件一定存在，不需要对错误进行处理
		data, _ = getFileFromRedis(fileName) //这里fileName还需调整，这个fileName此时并不唯一
		logger.Println("get from redis")
		return
    }

	// 如果程序运行到这里，说明内存没有命中，那么从硬盘中加载

	// 获得文件的字节流
	data, err = getFileStream(filePath)
	if err != nil {
		// fmt.Println("getFileStream err:", err)
		logger.Printf("getFileStream err:%v\n", err)
		return
	}
	/*
		在这里加入逻辑，决定缓存至内存中的策略
	*/

	// 将获取到的字节流送到redis中
	err = loadFileToRedis(fileName, data)
	if err != nil {
		// fmt.Println("loadFileToRedis err:", err)
		logger.Printf("loadFileToRedis err:%v\n", err)
		return data, err
	} else if opErr, ok := err.(*net.OpError); ok {
		if opErr.Timeout() {
			logger.Printf("tiomeout operation:%v\n", opErr.Op)
		} else {
			logger.Printf("err operation:%v\n", opErr.Op)
		}
		return data, err
	}

	// 都没有错误，返回数据
	// fmt.Println("get from disk")
	logger.Println("get from disk")
	return
}
```

# 阶段四

## 完成度

目前项目已经基本完成，已经可以基本可以用了。已经实现了redis热点缓存，日志文件的基本记载和自动生成，通过json文件进行项目的配置。目前未完成的尚在设想的功能有一键清除缓存，预加载的功能。

## 遇到的问题


1. 如何记录文件的访问次数以及判断缓存的逻辑。决定采用hash对象的方式储存数据，hash对象中有数据本身以及数据的访问次数，数据一开始被访问的时候先创建这个数据的key以及储存这个数据的access，也就是访问次数，但是不存放这个文件的数据的本身。等到这个数据符合热点数据的逻辑是就将数据本身缓存至内存中，等到数据的访问次数达到一个阈值的时候就将这个数据的ttl重置，即热点数据会常驻在内存之中。
2. 定时创建日志log问题。功能是让程序在每天的零点可以自动创建记录日志的文件，这个功能可以通过golang中time包的timer完成。让程序计算出每次距离下个零点的时间，然后用这个时间设置一个timer，之后一直监听这个timer，当这个timer提醒时，将目前的文件关闭并且新建一个日志文件。需要注意的是要在主协程中启动一个子协程用来监听timer,这个协程中要使用一个for无限循环，不然创建日志的动作就只会执行一次之后就不会再执行。下面分别是主协程和子协程的代码

   ```go
   // 启动一个协程，让其监听timer对channel的操作，主协程
   go myLog.Listener()
    
   // 监听函数，监听是否有timer往通道里面发送数据，子协程
   // 执行对应的操作
   func (myLog *MyLogger) Listener() {
   
   	// 监听定时器的channel,当时间到了就创建一个新的定时器
   	// 改进?:第一次setTimer可以使用一个一次性的timer,之后
   	// 程序运行是会稳定在24h之后创建日志文件，可以使用ticker
   	for range myLog.timer.C {
   		fmt.Println("time is up:", time.Now().Format("2006-01-02 15:04:05"))
   		myLog.createLogFileAuto()
   		nextTime := getNextCreateTime()
   		myLog.timer.Reset(nextTime)
   	}
   
   }
   ```

## 现在遇到的问题

在日志操作中，有很多处如下的操作。这两句的代码的意思是在数据返回前将信息记录到日志文件中，那么这样的操作就会带来一个很严重的问题。

```go
myLog.dailyLogger.Println("get from disk:" /*filePath*/)
return data, err
```

### 问题详情

第一行代码会将指定的日志内容输出到指定的日志文件中，然后第二行代码会将获取的数据返回。这两行代码是顺序执行的。这就会导致一个问题，数据的返回需要等待日志写完。那么，如果短时间内如果有大量的请求，就会带来大量的文件写操作，而文件的写操作是需要系统调用的，大量的系统调用随之而来的是频繁的操作系统状态(内核态和用户态)的反复切换，这种状态切换所需的时间是非常大的(相对计算机）。那么，如果有大量的写操作，就会导致很多写操作被阻塞在程序调用系统io接口，同样的，日志的写操作被阻塞了，数据的返回操作也会被阻塞。这样子前端需要过很久才能接受到数据，用户的体验会非常的糟糕，而且严重浪费了大量的cpu资源，因为cpu时间大量花费在上下文切换上了。经过验证也确实是这个问题，将代码中有的`dailyLogger`的操作注释后，网站就不卡顿了，而且cpu的占用也下来了。

### 解决方案

这种问题不算罕见，更多的因为项目的经验少，所以会没注意到这种细节。目前设想的解决方案是给程序添加一个缓冲区，等缓存区满了再写入日志文件中，并且将写日志操作变成异步操作，让数据的返回不需要等待写操作的完成，优化用户体验。需要注意的是，缓冲区是程序中全局唯一的存在，而且写操作是异步，并发的，这就涉及到了缓存区数据竞争的问题，需要对缓冲区上锁。而且在程序退出之前（不管正常还是异常），都需要将缓存区的内容写到日志文件中去，不然就会丢失一部分日志。

### 小记  

之前说的对缓存区上锁的操作可以不用了，因为log类型会是多线程安全的，他会保证对io.Writer接口的顺序访问。但是作为练习，我在一个demo中粗略实现了一个锁的操作。代码如下，这里简单的使用channel对loggerBuf的访问进行了类似于上锁的操作。

```go
package main

import (
	"bufio"
	"fmt"
	"os"
	"sync"
)

type loggerBuf struct {
	mu  chan int
	buf *bufio.Writer
}

func main() {

	lb := newLoggerBuf()

    // 给channel先填充一个，表明buf空闲
	lb.mu <- 1

    // 用来阻塞主协程
	var wg sync.WaitGroup

	for i := 0; i < 10; i++ {
		str := fmt.Sprintf("this is test%d\n", i)
		wg.Add(1)
		go func(str string) {
			n, err := lb.writeToBuf([]byte(str))
			if err != nil {
				fmt.Printf("written %d\n", n)
			}
			wg.Done()
		}(str)

	}
	wg.Wait()
	err := lb.buf.Flush()
	if err != nil {
		panic(err)
	}
	fmt.Println()

}

func newLoggerBuf() *loggerBuf {
	test, err := os.OpenFile("./test.txt", os.O_APPEND|os.O_RDWR, 0666)
	if err != nil {
		panic(err)
	}

	return &loggerBuf{
		mu:  make(chan int, 1),
		buf: bufio.NewWriterSize(test, 100),
	}
}

// 将数据写入buf中，如果buf空间不够会自动flush
func (lb *loggerBuf) writeToBuf(p []byte) (n int, err error) {
	// 从channel读取，如果channel中没有数据
	// 说明有人在使用buf，方法会被阻塞在这里
	<-lb.mu

	// 比较写入长度以及buf剩下可使用的长度
	if len(p) > lb.buf.Available() {
		// 写入的更长,先flush一波
		err = lb.buf.Flush()
		if err != nil {
			fmt.Println("err:", err)
			return 0, err
		}
		fmt.Println("short")
		// 将数据写入buf中
		n, err = lb.buf.Write(p)
		if err != nil {
			fmt.Println("err:", err)
			return
		}
	} else {
		// 剩下的空间够
		n, err = lb.buf.Write(p)
		if err != nil {
			fmt.Println("err:", err)
			return 0, err
		}
	}

	// 写数据到channel，相当于释放buf资源
	lb.mu <- 1
	return

}
```

那么对缓存区的访问就不需要上锁，但是需要注意的是缓存区可能需要定时flush,不然调试的时候可能会看不到日志文件。


:::info
那么对bufio.writer的flush()操作需不需要上锁呢

:::

答案是需要的，因为这个bufio.writer就不是并发安全的，所有的对bufio.writer执行异步，并发的操作都需要注意数据竞争的问题，那么为什么这个项目中就不需要呢。这是因为我们的日志操作最终都是通过，下面的代码写入日志的。但是log.Logger类型的print()方法里面已经实现了互斥锁，所以对log类型的对象访问时并发安全的，他会保证对io.writer接口的顺序访问。

```go
ml.dailyLogger.Println()
ml.errorLogger.Println()
```

### 补充

上文中提到的，不需要针对logBuf和执行上锁的操作是不对的，因为log只能保证每个logger对io接口的访问是并发安全的，但是如果有其他地方也对这个io接口执行操作的话，同样会引发数据竞争的问题，log并不能保证其他地方的访问io接口的行为是并发安全的。在这个项目中，就是指对buf的flush操作，如果在flush的同时写日志了，那么就会导致数据竞争的问题，又可能会导致程序的崩溃。下面简单介绍一下带锁的缓存。

logger由一个叫MyLogger的结构体描述，里面的有两个计时器，一个日常日志结构体，一个异常日志结构体，一个日常日志的缓存，一个异常日志的缓存。`ticker`计时器在指定的时间后执行操作，并不断重复，这里用来定时刷新日志。`timer`计时器用于在每天的零点定时创建新的日志文件及其所需的文件夹，Timer类型的定时器只会执行一次，所以需要在创建新的日志文件的同时重置定时器。`DailyLog`和`ErrorLog`分别用于管理日常日志和异常日志。`DailyBuf`和`ErrorBug`分别是日常日志和异常日志的缓存区。关于异步并发的操作，与上文中的一致，这里不再说明。

```go
// 一个自定义的logger结构体，包含了日常日志和错误日志
type MyLogger struct {
	ticker *time.Ticker
	timer  *time.Timer
	DailyLog
	ErrorLog
	DailyBuf
	ErrorBuf
}

// 日常日志
type DailyLog struct {
	dailyLogger *log.Logger
	dailyFile   *os.File
}

// 错误日志
type ErrorLog struct {
	errorLogger *log.Logger
	errorFile   *os.File
}

// 带锁的缓存
type DailyBuf struct {
	dmu     chan bool
	dbuffer *bufio.Writer
}

type ErrorBuf struct {
	emu     chan bool
	ebuffer *bufio.Writer
}
```


:::warning
切记！再使用channel做并发控制的时候，千万记得**初始化**channel以及往channel里面**添加值**，否则可能会造成某写操作的**永久阻塞**！

:::